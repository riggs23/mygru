{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfEwNIDnzuWm8Pk0KUQKCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riggs23/mygru/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5mFSUlqjWac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15fa319c-f445-4aea-ce93-f10ed65033ab"
      },
      "source": [
        "#JTV version\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime as dt\n",
        "import warnings;\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "from keras.metrics import TopKCategoricalAccuracy as topk\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY6gWK9AeB9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean up data\n",
        "data = pd.read_csv('jtv_dat')\n",
        "data.columns = ['SessionId', 'TimeStr', 'ItemId']\n",
        "#temp make data really small\n",
        "data = data.iloc[:50000,]\n",
        "data['Time'] = data.TimeStr.apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S').timestamp()) #This is not UTC. It does not really matter.\n",
        "del(data['TimeStr'])\n",
        "#data = data.astype({'ItemId': 'str'})"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLOVlSxYGZXE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtzbarxiTp3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "c5b69f50-4be5-425d-b895-f601ca900395"
      },
      "source": [
        "'''start = time.time()\n",
        "min_sess_len = 4\n",
        "session_lengths = data.groupby('SessionId').size()\n",
        "data = data[np.isin(data.SessionId, session_lengths[session_lengths>=min_sess_len].index)] #filters out 1-purchase sessions\n",
        "item_supports = data.groupby('ItemId').size()\n",
        "data = data[np.isin(data.ItemId, item_supports[item_supports>=8].index)] #filters out items that have been bought on less then 3 times\n",
        "session_lengths = data.groupby('SessionId').size()\n",
        "data = data[np.isin(data.SessionId, session_lengths[session_lengths>=min_sess_len].index)]#filters out newly-formed 1-purchase sessions\n",
        "\n",
        "\n",
        "session_max_times = data.groupby('SessionId').Time.max()\n",
        "tsep = np.quantile(session_max_times, .9)\n",
        "session_train = session_max_times[session_max_times < tsep].index #train is first 90% of data\n",
        "session_test = session_max_times[session_max_times >= tsep].index\n",
        "train = data[np.isin(data.SessionId, session_train)]\n",
        "test = data[np.isin(data.SessionId, session_test)]\n",
        "\n",
        "session_max_times = train.groupby('SessionId').Time.max()\n",
        "tsep = np.quantile(session_max_times, .8)\n",
        "session_train = session_max_times[session_max_times < tsep].index\n",
        "session_valid = session_max_times[session_max_times >= tsep].index\n",
        "train_tr = train[np.in1d(train.SessionId, session_train)]\n",
        "valid = train[np.in1d(train.SessionId, session_valid)]\n",
        "\n",
        "tslength = train_tr.groupby('SessionId').size()\n",
        "train_tr = train_tr[np.in1d(train_tr.SessionId, tslength[tslength>=min_sess_len].index)] #gets rid of new 1-purchase sessions\n",
        "\n",
        "valid = valid[np.in1d(valid.ItemId, train_tr.ItemId)] #gets rid of validation items not in train\n",
        "tslength = valid.groupby('SessionId').size()\n",
        "valid = valid[np.in1d(valid.SessionId, tslength[tslength>=min_sess_len].index)] #gets rid of new 1-purchase sessions\n",
        "\n",
        "test = test[np.isin(test.ItemId, train_tr.ItemId)] #gets rid of items not in train set. \n",
        "tslength = test.groupby('SessionId').size()\n",
        "test = test[np.isin(test.SessionId, tslength[tslength>=min_sess_len].index)]#gets rid of any new 1-purchase sessions\n",
        "print('Train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(train_tr), train_tr.SessionId.nunique(), train_tr.ItemId.nunique()))\n",
        "print('Validation set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(valid), valid.SessionId.nunique(), valid.ItemId.nunique()))\n",
        "print('Test set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(test), test.SessionId.nunique(), test.ItemId.nunique()))\n",
        "end = time.time()\n",
        "print(\"Time:\", (end-start)/60, \"mins\")\n",
        "del train'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'start = time.time()\\nmin_sess_len = 4\\nsession_lengths = data.groupby(\\'SessionId\\').size()\\ndata = data[np.isin(data.SessionId, session_lengths[session_lengths>=min_sess_len].index)] #filters out 1-purchase sessions\\nitem_supports = data.groupby(\\'ItemId\\').size()\\ndata = data[np.isin(data.ItemId, item_supports[item_supports>=8].index)] #filters out items that have been bought on less then 3 times\\nsession_lengths = data.groupby(\\'SessionId\\').size()\\ndata = data[np.isin(data.SessionId, session_lengths[session_lengths>=min_sess_len].index)]#filters out newly-formed 1-purchase sessions\\n\\n\\nsession_max_times = data.groupby(\\'SessionId\\').Time.max()\\ntsep = np.quantile(session_max_times, .9)\\nsession_train = session_max_times[session_max_times < tsep].index #train is first 90% of data\\nsession_test = session_max_times[session_max_times >= tsep].index\\ntrain = data[np.isin(data.SessionId, session_train)]\\ntest = data[np.isin(data.SessionId, session_test)]\\n\\nsession_max_times = train.groupby(\\'SessionId\\').Time.max()\\ntsep = np.quantile(session_max_times, .8)\\nsession_train = session_max_times[session_max_times < tsep].index\\nsession_valid = session_max_times[session_max_times >= tsep].index\\ntrain_tr = train[np.in1d(train.SessionId, session_train)]\\nvalid = train[np.in1d(train.SessionId, session_valid)]\\n\\ntslength = train_tr.groupby(\\'SessionId\\').size()\\ntrain_tr = train_tr[np.in1d(train_tr.SessionId, tslength[tslength>=min_sess_len].index)] #gets rid of new 1-purchase sessions\\n\\nvalid = valid[np.in1d(valid.ItemId, train_tr.ItemId)] #gets rid of validation items not in train\\ntslength = valid.groupby(\\'SessionId\\').size()\\nvalid = valid[np.in1d(valid.SessionId, tslength[tslength>=min_sess_len].index)] #gets rid of new 1-purchase sessions\\n\\ntest = test[np.isin(test.ItemId, train_tr.ItemId)] #gets rid of items not in train set. \\ntslength = test.groupby(\\'SessionId\\').size()\\ntest = test[np.isin(test.SessionId, tslength[tslength>=min_sess_len].index)]#gets rid of any new 1-purchase sessions\\nprint(\\'Train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}\\'.format(len(train_tr), train_tr.SessionId.nunique(), train_tr.ItemId.nunique()))\\nprint(\\'Validation set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}\\'.format(len(valid), valid.SessionId.nunique(), valid.ItemId.nunique()))\\nprint(\\'Test set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}\\'.format(len(test), test.SessionId.nunique(), test.ItemId.nunique()))\\nend = time.time()\\nprint(\"Time:\", (end-start)/60, \"mins\")\\ndel train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trsqSaQ2A4fR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6914b2a5-3acd-4fc2-e568-cf8f97523604"
      },
      "source": [
        "#not time sorted\n",
        "min_item_supports = 8\n",
        "min_sess_len = 6\n",
        "start = time.time()\n",
        "session_lengths = data.groupby('SessionId').size()\n",
        "data = data[np.isin(data.SessionId, session_lengths[session_lengths>=min_sess_len].index)] #filters out 1-purchase sessions\n",
        "item_supports = data.groupby('ItemId').size()\n",
        "data = data[np.isin(data.ItemId, item_supports[item_supports>=min_item_supports].index)] #filters out items that have been bought on less then 3 times\n",
        "session_lengths = data.groupby('SessionId').size()\n",
        "data = data[np.isin(data.SessionId, session_lengths[session_lengths>=min_sess_len].index)]#filters out newly-formed 1-purchase sessions\n",
        "\n",
        "\n",
        "sessions = data.SessionId.unique()\n",
        "random.shuffle(sessions)\n",
        "session_train = sessions[0:np.round(.9*len(sessions)).astype(int)]\n",
        "session_test = sessions[np.round(.9*len(sessions)).astype(int):]\n",
        "train = data[np.isin(data.SessionId, session_train)]\n",
        "test_data = data[np.isin(data.SessionId, session_test)]\n",
        "sessions = train.SessionId.unique()\n",
        "random.shuffle(sessions)\n",
        "session_train = sessions[0:np.round(.75*len(sessions)).astype(int)]\n",
        "session_valid = sessions[np.round(.75*len(sessions)).astype(int):]\n",
        "train_data = train[np.isin(train.SessionId, session_train)]\n",
        "#dev_data = train[np.isin(train.SessionId, session_valid)]\n",
        "valid_data = train[np.isin(train.SessionId, session_valid)]\n",
        "\n",
        "#get rid of duplicate purchases\n",
        "train_data = train_data[~((train_data.iloc[:, 0] == train_data.shift().iloc[:, 0]) & (train_data.iloc[:, 1] ==  train_data.shift().iloc[:, 1]))].reset_index(drop = True)\n",
        "tslength = train_data.groupby('SessionId').size()\n",
        "train_data = train_data[np.isin(train_data.SessionId, tslength[tslength>=min_sess_len].index)] #gets rid of new 1-purchase sessions\n",
        "\n",
        "#dev_data = dev_data[np.isin(dev_data.ItemId, train_data.ItemId)] #gets rid of validation items not in train\n",
        "valid_data = valid_data[np.isin(valid_data.ItemId, train_data.ItemId)] #gets rid of validation items not in train\n",
        "#tslength = dev_data.groupby('SessionId').size()\n",
        "valid_data = valid_data[~((valid_data.iloc[:, 0] == valid_data.shift().iloc[:, 0]) & (valid_data.iloc[:, 1] ==  valid_data.shift().iloc[:, 1]))].reset_index(drop = True)\n",
        "tslength = valid_data.groupby('SessionId').size()\n",
        "#dev_data = dev_data[np.isin(dev_data.SessionId, tslength[tslength>=min_sess_len].index)] #gets rid of new 1-purchase sessions\n",
        "valid_data = valid_data[np.isin(valid_data.SessionId, tslength[tslength>=min_sess_len].index)] #gets rid of new 1-purchase sessions\n",
        "\n",
        "test_data = test_data[np.isin(test_data.ItemId, train_data.ItemId)] #gets rid of items not in train set.\n",
        "test_data = test_data[~((test_data.iloc[:, 0] == test_data.shift().iloc[:, 0]) & (test_data.iloc[:, 1] ==  test_data.shift().iloc[:, 1]))].reset_index(drop = True)\n",
        "tslength = test_data.groupby('SessionId').size()\n",
        "test_data = test_data[np.isin(test_data.SessionId, tslength[tslength>=min_sess_len].index)]#gets rid of any new 1-purchase sessions\n",
        "\n",
        "print('Train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(train_data), train_data.SessionId.nunique(), train_data.ItemId.nunique()))\n",
        "#print('Dev set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(dev_data), dev_data.SessionId.nunique(), dev_data.ItemId.nunique()))\n",
        "print('Valid set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(valid_data), valid_data.SessionId.nunique(), valid_data.ItemId.nunique()))\n",
        "print('Test set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(test_data), test_data.SessionId.nunique(), test_data.ItemId.nunique()))\n",
        "end = time.time()\n",
        "print(\"Time:\", (end-start)/60, \"mins\")\n",
        "del train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set\n",
            "\tEvents: 7424\n",
            "\tSessions: 321\n",
            "\tItems: 946\n",
            "Valid set\n",
            "\tEvents: 2413\n",
            "\tSessions: 107\n",
            "\tItems: 833\n",
            "Test set\n",
            "\tEvents: 944\n",
            "\tSessions: 48\n",
            "\tItems: 562\n",
            "Time: 0.0008952816327412924 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swH_ZyoqaDR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ab46ef4a-bbf9-48a7-c529-30e2cdc60b39"
      },
      "source": [
        "#unique vocab for our data set - assign each product to a number\n",
        "train_itemids = train_data['ItemId'].unique()\n",
        "n_items = len(train_itemids)\n",
        "train_itemidmap = pd.Series(data=np.arange(1, n_items + 1), index=train_itemids, name='ItemIdx') #don't want zero as index, it will be padding num\n",
        "'''#train_itemidmap = dict(zip(train_itemids, np.arange(1, n_items + 1)))\n",
        "train_tr['ItemIdx'] = train_itemidmap[train_tr['ItemId'].values].values\n",
        "#test\n",
        "test_itemids = test['ItemId'].unique()\n",
        "test['ItemIdx'] = train_itemidmap[test['ItemId'].values].values\n",
        "#valid\n",
        "valid_itemids = valid['ItemId'].unique()\n",
        "valid['ItemIdx'] = train_itemidmap[valid['ItemId'].values].values'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"#train_itemidmap = dict(zip(train_itemids, np.arange(1, n_items + 1)))\\ntrain_tr['ItemIdx'] = train_itemidmap[train_tr['ItemId'].values].values\\n#test\\ntest_itemids = test['ItemId'].unique()\\ntest['ItemIdx'] = train_itemidmap[test['ItemId'].values].values\\n#valid\\nvalid_itemids = valid['ItemId'].unique()\\nvalid['ItemIdx'] = train_itemidmap[valid['ItemId'].values].values\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJZ91ujPTzpz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f33d79c9-19c2-4dee-c67c-41721384a997"
      },
      "source": [
        "customers_train = train_data[\"SessionId\"].unique().tolist()\n",
        "# populate the list with the product codes\n",
        "start = time.time()\n",
        "purchases_train = [train_data[train_data[\"SessionId\"] == i]['ItemId'].tolist() for i in customers_train]\n",
        "end = time.time()\n",
        "end - start\n",
        "\n",
        "customers_test = test_data[\"SessionId\"].unique().tolist()\n",
        "start = time.time()\n",
        "purchases_test = [test_data[test_data[\"SessionId\"] == i][\"ItemId\"].tolist() for i in customers_test]\n",
        "end = time.time()\n",
        "end - start\n",
        "\n",
        "customers_val = valid_data[\"SessionId\"].unique().tolist()\n",
        "start = time.time()\n",
        "purchases_val = [valid_data[valid_data[\"SessionId\"] == i][\"ItemId\"].tolist() for i in customers_val]\n",
        "end = time.time()\n",
        "end - start"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0607607364654541"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TN09xHWUdrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "##################### get the number to pad with\n",
        "def get_max(mylist):\n",
        "  max_len = 0\n",
        "  for i in mylist:\n",
        "    h = max(len(elem) for elem in i)\n",
        "    if h > max_len:\n",
        "      max_len = h\n",
        "  return max_len\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1lwejLZGmVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04cf0003-a1ed-421f-8c11-9f52c2e3aad4"
      },
      "source": [
        "purchases_train[1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4051330, 3965814, 4025826, 4070991, 4027137, 3753967]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGEfg-hCU0TP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "17a09a7f-e0e4-44c0-9ec4-6bf38ff77df6"
      },
      "source": [
        "'''#add element ot other two lists of length longest_list\n",
        "purchases_train.append(list(map(int, np.zeros(61))))\n",
        "purchases_val.append(list(map(int, np.zeros(61))))'''"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'#add element ot other two lists of length longest_list\\npurchases_train.append(list(map(int, np.zeros(61))))\\npurchases_val.append(list(map(int, np.zeros(61))))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltmza2AUGZ4R",
        "colab_type": "text"
      },
      "source": [
        "# Language Modeling LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KciA95hrr4WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f06eb1b3-1d7b-4eb4-fe66-9c424d024b54"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "else:\n",
        "  print(\"using GPU\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXZDJ7yvI4Yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sequence_len = get_max([purchases_train, purchases_val, purchases_test])\n",
        "total_words = len(train_itemidmap) + 1\n",
        "\n",
        "def dataset_preparation(data, mapper):\n",
        "\n",
        "  #total_words = len(mapper) + 1\n",
        "\n",
        "  input_sequences = []\n",
        "  extra_words = []\n",
        "  for line in data:\n",
        "    token_list = mapper.loc[line].tolist() #change jtv items to tokens\n",
        "    #use this to get sequences like [1, 12, 123, 1234]\n",
        "    #for i in range(1, len(token_list)):\n",
        "      #n_gram_sequence = token_list[:i+1]\n",
        "      #extra_sequence = token_list[i+1:]\n",
        "      #input_sequences.append(n_gram_sequence)\n",
        "      #extra_words.append(extra_sequence)\n",
        "    #use this to get sequences like [123, 234, 345]\n",
        "    #use min_sess_len instead of 4\n",
        "    for i in range(0, len(token_list) - (5- 1)):\n",
        "      n_gram_sequence = token_list[i:i+5]\n",
        "      input_sequences.append(n_gram_sequence)\n",
        "\n",
        "  # pad sequences \n",
        "  input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "  # create predictors and label\n",
        "  predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "  label = ku.to_categorical(label, num_classes=total_words)\n",
        "\n",
        "  return predictors, label\n",
        "\n",
        "\n",
        "def generate_text(seed_text, next_words, max_sequence_len, mapper):\n",
        "  products = seed_text.copy()\n",
        "  for _ in range(next_words):\n",
        "    itemized = mapper.loc[products].values.tolist()\n",
        "    token_list = pad_sequences([itemized], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict_classes(token_list, verbose=0)\n",
        "    output_item = mapper.keys()[predicted.item() - 1]\n",
        "    products.append(output_item)\n",
        "  return products"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfPOJyd3XlTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "c54ea1cc-5b67-4833-cfe0-af203a1a96a8"
      },
      "source": [
        "'''def create_model(predictors, label, max_sequence_len, total_words, i, j, k, l, m, valid_predictors = None, valid_label = None):\n",
        "  epochs = 5\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(total_words, i, input_length=max_sequence_len-1, mask_zero=True))\n",
        "  model.add(Dropout(j))\n",
        "  model.add(LSTM(l, return_sequences = False))\n",
        "  model.add(Dropout(k))\n",
        "  #model.add(LSTM(8))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "  #opt = tf.keras.optimizers.Nadam(learning_rate=0.0003, beta_1=.7, beta_2=.8)\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate= m)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[topk(k=5)])\n",
        "  earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='auto')\n",
        "  #, callbacks=[earlystop]in the model.fit\n",
        "  h = model.fit(predictors, label, epochs=epochs, verbose=1,  batch_size= 128, validation_data = (valid_predictors, valid_label)) #history\n",
        "  print(model.summary())\n",
        "\n",
        "\n",
        "  return model, h'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"def create_model(predictors, label, max_sequence_len, total_words, i, j, k, l, m, valid_predictors = None, valid_label = None):\\n  epochs = 5\\n  model = Sequential()\\n  model.add(Embedding(total_words, i, input_length=max_sequence_len-1, mask_zero=True))\\n  model.add(Dropout(j))\\n  model.add(LSTM(l, return_sequences = False))\\n  model.add(Dropout(k))\\n  #model.add(LSTM(8))\\n  #model.add(Dropout(0.2))\\n  model.add(Dense(total_words, activation='softmax'))\\n\\n  #opt = tf.keras.optimizers.Nadam(learning_rate=0.0003, beta_1=.7, beta_2=.8)\\n  opt = tf.keras.optimizers.Adam(learning_rate= m)\\n  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[topk(k=5)])\\n  earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='auto')\\n  #, callbacks=[earlystop]in the model.fit\\n  h = model.fit(predictors, label, epochs=epochs, verbose=1,  batch_size= 128, validation_data = (valid_predictors, valid_label)) #history\\n  print(model.summary())\\n\\n\\n  return model, h\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJOM8UKIZ1uZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "25c28acf-3d09-4049-b98d-0218b18b411b"
      },
      "source": [
        "'''predictors, label = dataset_preparation(purchases_train, train_itemidmap)\n",
        "valid_predictors, valid_label = dataset_preparation(purchases_val, train_itemidmap)\n",
        "test_predictors, test_label = dataset_preparation(purchases_test, train_itemidmap)\n",
        "#parameters to adjust\n",
        "sizer = [175]\n",
        "drop_1 = [.7]\n",
        "drop_2 = [0, .2, .7]\n",
        "LSTM_size = [64, 128]\n",
        "l_r = [.0003, .003]\n",
        "z = 1\n",
        "zz = []\n",
        "for i in sizer:\n",
        "  for j in drop_1:\n",
        "    for k in drop_2:\n",
        "      for l in LSTM_size:\n",
        "        for m in l_r:\n",
        "          model, h= create_model(predictors, label, max_sequence_len, total_words, i=1, j=j, k=k, l=l, m=m, valid_label=valid_label, valid_predictors=valid_predictors)\n",
        "          print(z)\n",
        "          test_acc = model.evaluate(test_predictors, test_label, verbose=0)[1]\n",
        "          print(\"Test Accuracy: \",np.round(test_acc,4))\n",
        "          zz.append(np.round(test_acc, 4))\n",
        "          plt.plot(h.history['loss'], label='Train loss')\n",
        "          plt.plot(h.history['val_loss'], label='Validation loss')\n",
        "          plt.xlabel('Epochs')\n",
        "          plt.ylabel('Loss')\n",
        "          plt.legend(['Train_loss', 'Validation_loss'])\n",
        "          #plt.savefig('Loss'+str(z))\n",
        "          plt.show()\n",
        "\n",
        "          plt.plot(h.history['top_k_categorical_accuracy'], label='Train accuracy')\n",
        "          plt.plot(h.history['val_top_k_categorical_accuracy'], label='Validation accuracy')\n",
        "          plt.xlabel('Epochs')\n",
        "          plt.ylabel('Accuracy')\n",
        "          plt.legend(['Train_acc', 'Validation_acc'])\n",
        "          #plt.savefig('Accuray'+str(z))\n",
        "          plt.show()\n",
        "          z += 1\n",
        "\n",
        "          \n",
        "\n",
        "'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'predictors, label = dataset_preparation(purchases_train, train_itemidmap)\\nvalid_predictors, valid_label = dataset_preparation(purchases_val, train_itemidmap)\\ntest_predictors, test_label = dataset_preparation(purchases_test, train_itemidmap)\\n#parameters to adjust\\nsizer = [175]\\ndrop_1 = [.7]\\ndrop_2 = [0, .2, .7]\\nLSTM_size = [64, 128]\\nl_r = [.0003, .003]\\nz = 1\\nzz = []\\nfor i in sizer:\\n  for j in drop_1:\\n    for k in drop_2:\\n      for l in LSTM_size:\\n        for m in l_r:\\n          model, h= create_model(predictors, label, max_sequence_len, total_words, i=1, j=j, k=k, l=l, m=m, valid_label=valid_label, valid_predictors=valid_predictors)\\n          print(z)\\n          test_acc = model.evaluate(test_predictors, test_label, verbose=0)[1]\\n          print(\"Test Accuracy: \",np.round(test_acc,4))\\n          zz.append(np.round(test_acc, 4))\\n          plt.plot(h.history[\\'loss\\'], label=\\'Train loss\\')\\n          plt.plot(h.history[\\'val_loss\\'], label=\\'Validation loss\\')\\n          plt.xlabel(\\'Epochs\\')\\n          plt.ylabel(\\'Loss\\')\\n          plt.legend([\\'Train_loss\\', \\'Validation_loss\\'])\\n          #plt.savefig(\\'Loss\\'+str(z))\\n          plt.show()\\n\\n          plt.plot(h.history[\\'top_k_categorical_accuracy\\'], label=\\'Train accuracy\\')\\n          plt.plot(h.history[\\'val_top_k_categorical_accuracy\\'], label=\\'Validation accuracy\\')\\n          plt.xlabel(\\'Epochs\\')\\n          plt.ylabel(\\'Accuracy\\')\\n          plt.legend([\\'Train_acc\\', \\'Validation_acc\\'])\\n          #plt.savefig(\\'Accuray\\'+str(z))\\n          plt.show()\\n          z += 1\\n\\n          \\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp8TzXxG-iQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(predictors, label, max_sequence_len, total_words, valid_predictors = None, valid_label = None, test_predictors = None, test_label = None):\n",
        "  epochs = 150\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(total_words, 60, input_length=max_sequence_len-1, mask_zero=True))\n",
        "  model.add(Dropout(.7))\n",
        "  model.add(LSTM(128, dropout=0.3, recurrent_dropout=0.3, return_sequences = True))\n",
        "  model.add(LSTM(64, dropout=0.3, recurrent_dropout=0.3, return_sequences=False))\n",
        "  #model.add(LSTM(32, dropout=0.5, recurrent_dropout=0.5))\n",
        "  #model.add(Dropout(.7))\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "  opt = tf.keras.optimizers.Nadam(learning_rate=0.003, beta_1=.7, beta_2=.8)\n",
        "  #opt = tf.keras.optimizers.Adam(learning_rate=.0003)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[topk(k=5)])\n",
        "  earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='auto')\n",
        "  #, callbacks=[earlystop]in the model.fit\n",
        "  #validation_data = (valid_predictors, valid_label),\n",
        "  h = model.fit(predictors, label, epochs=epochs, verbose=1,  batch_size= 128, validation_data = (valid_predictors, valid_label)) #history\n",
        "  print(model.summary())\n",
        "\n",
        "\n",
        "  return model, h"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tNwqf1k9qdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebFkKcSmHiS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "outputId": "25df1b90-73f7-4561-c39e-5d652c30a9c7"
      },
      "source": [
        "predictors, label = dataset_preparation(purchases_train, train_itemidmap)\n",
        "valid_predictors, valid_label = dataset_preparation(purchases_val, train_itemidmap)\n",
        "test_predictors, test_label = dataset_preparation(purchases_test, train_itemidmap)\n",
        "\n",
        "model, h= create_model(predictors, label, max_sequence_len, total_words, valid_label=valid_label, valid_predictors=valid_predictors)\n",
        "#, valid_label=valid_label, valid_predictors=valid_predictors\n",
        "#print(generate_text(purchases_train[1], 1, max_sequence_len, train_itemidmap))\n",
        "#test_acc = model.evaluate(test_predictors, test_label, verbose=0)[1]\n",
        "#print(\"Test Accuracy: \",np.round(test_acc,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6140 samples, validate on 1985 samples\n",
            "Epoch 1/150\n",
            "6140/6140 [==============================] - 111s 18ms/step - loss: 6.8227 - top_k_categorical_accuracy: 0.0207 - val_loss: 6.8272 - val_top_k_categorical_accuracy: 0.0302\n",
            "Epoch 2/150\n",
            "6140/6140 [==============================] - 109s 18ms/step - loss: 6.7325 - top_k_categorical_accuracy: 0.0259 - val_loss: 6.8700 - val_top_k_categorical_accuracy: 0.0307\n",
            "Epoch 3/150\n",
            "6140/6140 [==============================] - 111s 18ms/step - loss: 6.7048 - top_k_categorical_accuracy: 0.0277 - val_loss: 6.8481 - val_top_k_categorical_accuracy: 0.0338\n",
            "Epoch 4/150\n",
            "6140/6140 [==============================] - 109s 18ms/step - loss: 6.6820 - top_k_categorical_accuracy: 0.0274 - val_loss: 6.8816 - val_top_k_categorical_accuracy: 0.0307\n",
            "Epoch 5/150\n",
            "6140/6140 [==============================] - 110s 18ms/step - loss: 6.6649 - top_k_categorical_accuracy: 0.0275 - val_loss: 6.8892 - val_top_k_categorical_accuracy: 0.0292\n",
            "Epoch 6/150\n",
            "6140/6140 [==============================] - 108s 18ms/step - loss: 6.6413 - top_k_categorical_accuracy: 0.0295 - val_loss: 6.8886 - val_top_k_categorical_accuracy: 0.0302\n",
            "Epoch 7/150\n",
            "6140/6140 [==============================] - 109s 18ms/step - loss: 6.6215 - top_k_categorical_accuracy: 0.0272 - val_loss: 6.9374 - val_top_k_categorical_accuracy: 0.0292\n",
            "Epoch 8/150\n",
            "6140/6140 [==============================] - 110s 18ms/step - loss: 6.6036 - top_k_categorical_accuracy: 0.0300 - val_loss: 6.9295 - val_top_k_categorical_accuracy: 0.0277\n",
            "Epoch 9/150\n",
            "6140/6140 [==============================] - 109s 18ms/step - loss: 6.5801 - top_k_categorical_accuracy: 0.0288 - val_loss: 7.0033 - val_top_k_categorical_accuracy: 0.0272\n",
            "Epoch 10/150\n",
            "6140/6140 [==============================] - 112s 18ms/step - loss: 6.5539 - top_k_categorical_accuracy: 0.0308 - val_loss: 6.9419 - val_top_k_categorical_accuracy: 0.0242\n",
            "Epoch 11/150\n",
            "6140/6140 [==============================] - 110s 18ms/step - loss: 6.5447 - top_k_categorical_accuracy: 0.0300 - val_loss: 6.9583 - val_top_k_categorical_accuracy: 0.0252\n",
            "Epoch 12/150\n",
            "6140/6140 [==============================] - 108s 18ms/step - loss: 6.5287 - top_k_categorical_accuracy: 0.0319 - val_loss: 6.9842 - val_top_k_categorical_accuracy: 0.0282\n",
            "Epoch 13/150\n",
            "6140/6140 [==============================] - 109s 18ms/step - loss: 6.5224 - top_k_categorical_accuracy: 0.0309 - val_loss: 6.9791 - val_top_k_categorical_accuracy: 0.0282\n",
            "Epoch 14/150\n",
            "6140/6140 [==============================] - 109s 18ms/step - loss: 6.5086 - top_k_categorical_accuracy: 0.0318 - val_loss: 7.0381 - val_top_k_categorical_accuracy: 0.0272\n",
            "Epoch 15/150\n",
            "6140/6140 [==============================] - 107s 17ms/step - loss: 6.4928 - top_k_categorical_accuracy: 0.0334 - val_loss: 7.0033 - val_top_k_categorical_accuracy: 0.0262\n",
            "Epoch 16/150\n",
            "6140/6140 [==============================] - 107s 17ms/step - loss: 6.4817 - top_k_categorical_accuracy: 0.0360 - val_loss: 6.9898 - val_top_k_categorical_accuracy: 0.0292\n",
            "Epoch 17/150\n",
            "6140/6140 [==============================] - 106s 17ms/step - loss: 6.4590 - top_k_categorical_accuracy: 0.0350 - val_loss: 7.0066 - val_top_k_categorical_accuracy: 0.0247\n",
            "Epoch 18/150\n",
            "6140/6140 [==============================] - 106s 17ms/step - loss: 6.4331 - top_k_categorical_accuracy: 0.0350 - val_loss: 7.0557 - val_top_k_categorical_accuracy: 0.0247\n",
            "Epoch 19/150\n",
            "6140/6140 [==============================] - 106s 17ms/step - loss: 6.4171 - top_k_categorical_accuracy: 0.0368 - val_loss: 7.0459 - val_top_k_categorical_accuracy: 0.0237\n",
            "Epoch 20/150\n",
            "6140/6140 [==============================] - 107s 17ms/step - loss: 6.3843 - top_k_categorical_accuracy: 0.0427 - val_loss: 7.0654 - val_top_k_categorical_accuracy: 0.0262\n",
            "Epoch 21/150\n",
            "5504/6140 [=========================>....] - ETA: 10s - loss: 6.3542 - top_k_categorical_accuracy: 0.0447"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbNbPF4ZM7uf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "ed70758f-9f76-44cd-8181-b4da88c21125"
      },
      "source": [
        "plt.plot(h.history['loss'], label='Train loss')\n",
        "plt.plot(h.history['val_loss'], label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train_loss', 'Validation_loss'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(h.history['top_k_categorical_accuracy'], label='Train accuracy')\n",
        "plt.plot(h.history['val_top_k_categorical_accuracy'], label='Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train_acc', 'Validation_acc'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a46ce12755c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyMLK7Zxk5mF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "2669f523-1101-4ae4-de0f-56ae90352bd2"
      },
      "source": [
        "def plot(model, val_bool = True):\n",
        "  plt.plot(model.history['loss'], label='Train loss')\n",
        "  if val_bool:\n",
        "    plt.plot(model.history['val_loss'], label='Validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  if val_bool:\n",
        "    plt.legend(['Train_loss', 'Validation_loss'])\n",
        "  else:\n",
        "    plt.legend('Train_loss')\n",
        "  plt.show()\n",
        "  plt.plot(model.history['top_k_categorical_accuracy'], label='Train accuracy')\n",
        "  if val_bool:\n",
        "    plt.plot(model.history['val_top_k_categorical_accuracy'], label='Validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  if val_bool:\n",
        "    plt.legend(['Train_acc', 'Validation_acc'])\n",
        "  else:\n",
        "    plt.legend('Train_loss')\n",
        "  plt.show()\n",
        "\n",
        "plot(h, val_bool = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXSNY7q_YsyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing to make sure the model isn't getting rid of options to choose from!\n",
        "hh= []\n",
        "for i in range(len(test_predictors)):\n",
        "  hh.append(np.count_nonzero(model.predict(test_predictors[[i]])))\n",
        "for i in range(5):\n",
        "  print(hh.count(i) / len(hh))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBsAMDL4wHdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0291cb4f-2750-44d7-df62-6f280d1f36ab"
      },
      "source": [
        "token_list= train_itemidmap.loc[purchases_test[0][0:2]].tolist()\n",
        "token_list = np.array(pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre'))\n",
        "print(model.predict_proba(token_list).flatten())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00060733 0.0006254  0.00061685 ... 0.00061197 0.00061148 0.00062113]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXCE_HHHv9gm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "b6966f24-751e-4f96-eaa5-d67a704469d5"
      },
      "source": [
        "train_itemidmap[purchases_test[0]]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4050549     259\n",
              "4003156     162\n",
              "4069470    1359\n",
              "4051505    1380\n",
              "3616580    1396\n",
              "3551162     722\n",
              "3551157      44\n",
              "4081957     534\n",
              "4103889     533\n",
              "4049575     246\n",
              "4076737     183\n",
              "4084405      17\n",
              "3957504    1439\n",
              "4102273    1460\n",
              "4085856      42\n",
              "4168275    1274\n",
              "3966285    1447\n",
              "3754848     247\n",
              "Name: ItemIdx, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV5ReCDYFnKd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c4a58e0-885c-45e2-8212-33d2cf081223"
      },
      "source": [
        "'''print(purchases_test[0])\n",
        "print(generate_text(purchases_test[0][0:2], 1, max_sequence_len, train_itemidmap))\n",
        "print(generate_text(purchases_test[0][1:3], 1, max_sequence_len, train_itemidmap))\n",
        "print(generate_text(purchases_test[0][2:4], 1, max_sequence_len, train_itemidmap))\n",
        "print(generate_text(purchases_test[0][3:5], 1, max_sequence_len, train_itemidmap))\n",
        "print(generate_text(purchases_test[0][4:6], 1, max_sequence_len, train_itemidmap))\n",
        "print(generate_text(purchases_test[0][5:7], 1, max_sequence_len, train_itemidmap))'''\n",
        "\n",
        "#len(model.predict_proba(token_list).flatten().tolist())\n",
        "token_list = np.array(pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre'))\n",
        "model.predict_proba(token_list).flatten()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4116034, 4096912, 4096912, 4086085, 4086085, 4267228, 3559889, 3559885]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FYKKc45HkvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "5d4dcff4-3756-46e9-96df-f9b55dede8af"
      },
      "source": [
        "def visualize(tester_val, sub_seq_len):\n",
        "  print(\"Visualizing...\")\n",
        "  total_seq = train_itemidmap.loc[purchases_test[tester_val]].tolist()\n",
        "  print(total_seq)\n",
        "  for i in range(len(total_seq) - sub_seq_len):\n",
        "    token_list = total_seq[i:i+sub_seq_len]\n",
        "    yoyo = token_list\n",
        "    token_list = np.array(pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre'))\n",
        "    print(yoyo, \"-->\", model.predict_proba(token_list).flatten().argsort()[-5:][::-1].tolist(), \"Should ==\", total_seq[i+sub_seq_len])\n",
        "visualize(1, 4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Visualizing...\n",
            "[1350, 240, 1350, 213, 384, 439, 36, 1520, 337, 457, 1170, 1170]\n",
            "[1350, 240, 1350, 213] --> [1084, 227, 396, 879, 77] Should == 384\n",
            "[240, 1350, 213, 384] --> [227, 1049, 294, 137, 573] Should == 439\n",
            "[1350, 213, 384, 439] --> [164, 573, 520, 387, 396] Should == 36\n",
            "[213, 384, 439, 36] --> [573, 116, 1001, 43, 789] Should == 1520\n",
            "[384, 439, 36, 1520] --> [902, 1338, 116, 1343, 1291] Should == 337\n",
            "[439, 36, 1520, 337] --> [1338, 82, 1276, 1003, 547] Should == 457\n",
            "[36, 1520, 337, 457] --> [426, 1685, 521, 595, 1279] Should == 1170\n",
            "[1520, 337, 457, 1170] --> [526, 80, 2, 1111, 1663] Should == 1170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHDNJNr3zP2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ec104ccb-fa9d-4c4a-f964-36f398ae9586"
      },
      "source": [
        "def get_acc_seq_len(tester_val, sub_seq_len, extra_positives_len): #tester val for one\n",
        "  acc = []\n",
        "  print(\"Getting acc...\")\n",
        "  for i in tqdm(range(len(purchases_test))):\n",
        "    total_seq = train_itemidmap.loc[purchases_test[i]].tolist()\n",
        "    for i in range(len(total_seq) - sub_seq_len):\n",
        "      possibles = []\n",
        "      token_list = total_seq[i:i+sub_seq_len]\n",
        "      next_purch = total_seq[i + sub_seq_len]\n",
        "      #option 1 - next purchase is element of the sequence we're using to predict it --> accurate\n",
        "      #or, just continue without counting accuracy - maybe better\n",
        "      #if next_purch in token_list:\n",
        "        #acc.append(True)\n",
        "        #continue\n",
        "      #option 2 - next purchase is any element in the sequence already, even those before our sequence we're using. \n",
        "      if next_purch in total_seq[:i + sub_seq_len]:\n",
        "        acc.append(True)\n",
        "        continue\n",
        "      #get the top_k preds, but trim down to exclude those that have already been purchased\n",
        "      #yoyo = token_list\n",
        "      token_list = np.array(pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre'))\n",
        "      predictions = model.predict_proba(token_list).flatten().argsort()[-50:][::-1].tolist() #get 100??? but narrow down after\n",
        "      #if already purchased, don't recommend\n",
        "      #for i in reversed(range(len(predictions))):\n",
        "        #if predictions[i] in total_seq[:i+sub_seq_len]:\n",
        "          #predictions.remove(predictions[i])\n",
        "      predictions = predictions[0:5]\n",
        "      #now, check if next_purch or a few extras are in the recommended list. if so, call it good.\n",
        "      #might be risky - if i have three extras, and a few seqs in a row recommend that third item, i get three as good that aren't necessarily???\n",
        "      possibles = total_seq[i+sub_seq_len:i+sub_seq_len+extra_positives_len]\n",
        "      acc.append(any(check in possibles for check in predictions))\n",
        "  return np.round(np.mean(acc), 4)\n",
        "start = time.time()\n",
        "print(get_acc_seq_len(1,5,5))\n",
        "print(get_acc_seq_len(2,5,5))\n",
        "\n",
        "#print(\"3 seq, 3 after:\", get_acc_seq_len(3, 3, 3))\n",
        "'''print(\"3 seq, 4 after:\", get_acc_seq_len(3, 3, 4))\n",
        "print(\"4 seq, 3 after:\", get_acc_seq_len(3, 4, 3))\n",
        "print(\"5 seq, 3 after:\", get_acc_seq_len(3, 5, 3))\n",
        "print(\"5 seq, 4 after:\", get_acc_seq_len(3, 5, 4))'''\n",
        "\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print('time:', end-start, \"Seconds\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/90 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Getting acc...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|| 90/90 [13:25<00:00,  8.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.0211\n",
            "time: 805.2127313613892 Seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGJ9qpQfeJLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4144888-5dd3-49b8-cfa0-8993fb4d4f7c"
      },
      "source": [
        "test_acc = model.evaluate(test_predictors, test_label, verbose=0)[1]\n",
        "print(\"Test Accuracy: \",np.round(test_acc,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.0163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbTqXYAN4xQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "023b7aca-a207-4634-8d07-5d3e3e768298"
      },
      "source": [
        "model.predict_proba(token_list).flatten().argsort()[-5:][::-1].tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c07faa29e5a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'token_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5GyOISgpXSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_last_test():\n",
        "  input_sequences = []\n",
        "  token_list= []\n",
        "  for line in purchases_test:\n",
        "    token_list.append(train_itemidmap.loc[line].tolist()) #change jtv items to tokens\n",
        "    input_sequences = np.array(pad_sequences(token_list, maxlen=max_sequence_len, padding='pre'))\n",
        "  # create predictors and label\n",
        "  predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "  label = ku.to_categorical(label, num_classes=total_words)\n",
        "  return predictors, label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqOTQRDNFI5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1819dbb-acb6-4290-9abe-0bd00cc9779d"
      },
      "source": [
        "test_predictors, test_label = get_last_test()\n",
        "test_acc = model.evaluate(test_predictors, test_label, verbose=0)[1]\n",
        "print(\"Test Accuracy: \",np.round(test_acc,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjMtAJB6FLQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def revamped_acc():\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}